{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from joblib import dump, load\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = pd.read_csv('../datasets/winequality_red_x_train.csv')\n",
    "y_df = pd.read_csv('../datasets/winequality_red_y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split training and testing set \n",
    "x_train, x_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3  4  5  6  7  8\n",
       "0  0  1  0  0  0    360\n",
       "      0  1  0  0    349\n",
       "         0  1  0    101\n",
       "   1  0  0  0  0     28\n",
       "   0  0  0  0  1     11\n",
       "1  0  0  0  0  0      7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE\n",
    "Model with smote performed worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smote\n",
    "sm = SMOTE(random_state=0)\n",
    "x_train_res, y_train_res = sm.fit_resample(x_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_res = pd.DataFrame(y_train_res)\n",
    "y_train_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: commented out models cannot handle multiple columns in y_df\n",
    "models = [\n",
    "    # LogisticRegression(random_state=0), \n",
    "    MLPClassifier(random_state=0), \n",
    "    KNeighborsClassifier(), \n",
    "    # SVC(random_state=0),\n",
    "    # GaussianProcessClassifier(random_state=0), \n",
    "    # QuadraticDiscriminantAnalysis(), \n",
    "    DecisionTreeClassifier(random_state=0), \n",
    "    RandomForestClassifier(random_state=0), \n",
    "    # AdaBoostClassifier(random_state=0), \n",
    "    # GaussianNB()\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLPClassifier(random_state=0)\n",
      "0.21342379914928933\n",
      "\n",
      "KNeighborsClassifier()\n",
      "0.24660496068368562\n",
      "\n",
      "DecisionTreeClassifier(random_state=0)\n",
      "0.3188712777041624\n",
      "\n",
      "RandomForestClassifier(random_state=0)\n",
      "0.3051047120418848\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    try:\n",
    "        print('\\n' + str(model))\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        print(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "From Feature Relevance ntbk, remove columns `[\"citric acid\", \"density\", \"free sulfur dioxide\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.690265</td>\n",
       "      <td>0.157534</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.111853</td>\n",
       "      <td>0.222615</td>\n",
       "      <td>0.299213</td>\n",
       "      <td>0.251497</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.185841</td>\n",
       "      <td>0.431507</td>\n",
       "      <td>0.102740</td>\n",
       "      <td>0.110184</td>\n",
       "      <td>0.091873</td>\n",
       "      <td>0.637795</td>\n",
       "      <td>0.167665</td>\n",
       "      <td>0.676923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.176991</td>\n",
       "      <td>0.349315</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.135225</td>\n",
       "      <td>0.252650</td>\n",
       "      <td>0.362205</td>\n",
       "      <td>0.071856</td>\n",
       "      <td>0.169231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.566372</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>0.070117</td>\n",
       "      <td>0.045936</td>\n",
       "      <td>0.448819</td>\n",
       "      <td>0.329341</td>\n",
       "      <td>0.323077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.336283</td>\n",
       "      <td>0.428082</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.130217</td>\n",
       "      <td>0.201413</td>\n",
       "      <td>0.354331</td>\n",
       "      <td>0.293413</td>\n",
       "      <td>0.184615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>0.398230</td>\n",
       "      <td>0.328767</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.076795</td>\n",
       "      <td>0.014134</td>\n",
       "      <td>0.346457</td>\n",
       "      <td>0.179641</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>0.318584</td>\n",
       "      <td>0.352740</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>0.101836</td>\n",
       "      <td>0.190813</td>\n",
       "      <td>0.433071</td>\n",
       "      <td>0.251497</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>0.230088</td>\n",
       "      <td>0.342466</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.108514</td>\n",
       "      <td>0.279152</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.125749</td>\n",
       "      <td>0.169231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>0.292035</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.070117</td>\n",
       "      <td>0.031802</td>\n",
       "      <td>0.456693</td>\n",
       "      <td>0.281437</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>0.106195</td>\n",
       "      <td>0.116438</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.085142</td>\n",
       "      <td>0.017668</td>\n",
       "      <td>0.511811</td>\n",
       "      <td>0.125749</td>\n",
       "      <td>0.784615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1071 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  residual sugar  chlorides  \\\n",
       "0          0.690265          0.157534        0.116438   0.111853   \n",
       "1          0.185841          0.431507        0.102740   0.110184   \n",
       "2          0.176991          0.349315        0.232877   0.135225   \n",
       "3          0.566372          0.123288        0.082192   0.070117   \n",
       "4          0.336283          0.428082        0.068493   0.130217   \n",
       "...             ...               ...             ...        ...   \n",
       "1066       0.398230          0.328767        0.068493   0.076795   \n",
       "1067       0.318584          0.352740        0.082192   0.101836   \n",
       "1068       0.230088          0.342466        0.123288   0.108514   \n",
       "1069       0.292035          0.054795        0.054795   0.070117   \n",
       "1070       0.106195          0.116438        0.054795   0.085142   \n",
       "\n",
       "      total sulfur dioxide        pH  sulphates   alcohol  \n",
       "0                 0.222615  0.299213   0.251497  0.307692  \n",
       "1                 0.091873  0.637795   0.167665  0.676923  \n",
       "2                 0.252650  0.362205   0.071856  0.169231  \n",
       "3                 0.045936  0.448819   0.329341  0.323077  \n",
       "4                 0.201413  0.354331   0.293413  0.184615  \n",
       "...                    ...       ...        ...       ...  \n",
       "1066              0.014134  0.346457   0.179641  0.307692  \n",
       "1067              0.190813  0.433071   0.251497  0.384615  \n",
       "1068              0.279152  0.606299   0.125749  0.169231  \n",
       "1069              0.031802  0.456693   0.281437  0.538462  \n",
       "1070              0.017668  0.511811   0.125749  0.784615  \n",
       "\n",
       "[1071 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_features = [\"citric acid\", \"density\", \"free sulfur dioxide\"]\n",
    "\n",
    "x_df_0 = x_df.drop(drop_features, axis=1)\n",
    "\n",
    "x_df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier: 0.35668385633823424\n",
      "RandomForestClassifier: 0.2939881114748136\n"
     ]
    }
   ],
   "source": [
    "x_train_0, x_test_0, y_train_0, y_test_0 = train_test_split(x_df_0, y_df, test_size=0.2, random_state=0)\n",
    "\n",
    "#checking with decision tree\n",
    "model_01 = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "model_01.fit(x_train_0, y_train_0)\n",
    "pred_01 = model_01.predict(x_test_0)\n",
    "print('DecisionTreeClassifier: {}'.format(f1_score(y_test_0, pred_01, average=\"macro\")))\n",
    "\n",
    "#checking with random forest\n",
    "model_02 = RandomForestClassifier(random_state=0)\n",
    "\n",
    "model_02.fit(x_train_0, y_train_0)\n",
    "pred_02 = model_02.predict(x_test_0)\n",
    "print('RandomForestClassifier: {}'.format(f1_score(y_test_0, pred_02, average=\"macro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/clf_red_wine.joblib']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model_01, '../models/clf_red_wine.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_0\n",
    "y_train = y_train_0\n",
    "x_test = x_test_0\n",
    "y_test = y_test_0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "DecisionTree hyperparameter tuning. Hypertuned models did not result to a better f1 score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:10<00:00, 18.37trial/s, best loss: 0.5731131516447259]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 2,\n",
       " 'max_depth': 7,\n",
       " 'min_samples_leaf': 0,\n",
       " 'min_samples_split': 1,\n",
       " 'splitter': 1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define DecisionTreeClassifier Hyperparameters\n",
    "space = {'max_depth': hp.choice('max_depth', range(1,10)),\n",
    "         'criterion': hp.choice('criterion', [\"gini\",\"entropy\",\"log_loss\"]),\n",
    "         'min_samples_split': hp.choice('min_samples_split', range(1,10)),\n",
    "         'min_samples_leaf': hp.choice('min_samples_leaf', range(1,10)),\n",
    "         'splitter': hp.choice('splitter', [\"best\", \"random\"]),\n",
    "        }\n",
    "\n",
    "#define target function\n",
    "def objective(params):\n",
    "\n",
    "#create model instance with params\n",
    "    model = DecisionTreeClassifier(**params)\n",
    "\n",
    "#train model\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "#evaluate and return model score\n",
    "\n",
    "    scores = cross_val_score(model, x_train, y_train, cv=5, scoring='f1_macro')\n",
    "    \n",
    "    # Extract the best score\n",
    "    best_score = max(scores)\n",
    "\n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "#minimize target function with hyperopt\n",
    "best = fmin(objective,\n",
    "            space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=200)\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier: 0.25896172272358636\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=0, criterion=\"log_loss\", max_depth=8, splitter=\"random\")\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "pred = model.predict(x_test)\n",
    "print('DecisionTreeClassifier: {}'.format(f1_score(y_test, pred, average=\"macro\")))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1944 candidates, totalling 9720 fits\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "param_grid = {'max_depth': range(1,10),\n",
    "         'criterion':  [\"gini\",\"entropy\",\"log_loss\"],\n",
    "         'min_samples_split': range(1,10),\n",
    "         'min_samples_leaf': range(1,5),\n",
    "         'splitter':[\"best\", \"random\"],\n",
    "        }\n",
    "\n",
    "clf = GridSearchCV(model, param_grid = param_grid, verbose=1)\n",
    "best_clf = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 1, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "print(best_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier: 0.31611161107093394\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=0, criterion=\"gini\", max_depth=9, splitter=\"best\",min_samples_leaf= 1, min_samples_split= 1)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "pred = model.predict(x_test)\n",
    "print('DecisionTreeClassifier: {}'.format(f1_score(y_test, pred, average=\"macro\")))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKIPPED PARTS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning (skip)\n",
    "\n",
    "For hyperparameter tuning of original randomforestmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "param_grid = {   \n",
    "    # 'n_estimators' : [25, 50, 75, 100, 125, 150, 175, 200],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    # 'max_depth': [20, 40, 60, 80, 100, None],\n",
    "    'bootstrap': [True, False],\n",
    "    # 'min_samples_split' : [2, 3, 4, 5],\n",
    "    # 'min_samples_leaf' : [1, 2, 3, 4, 5],\n",
    "    'max_features' : ['sqrt', 'log2', 'auto', None],\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "clf = GridSearchCV(model, param_grid = param_grid, refit=True, verbose=3)\n",
    "best_clf = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'criterion': 'gini', 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "print(best_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "param_grid = [{   \n",
    "    'n_estimators' : [25, 50, 75, 100, 125, 150, 175, 200],\n",
    "    'max_depth': [20, 40, 60, 80, 100, None],\n",
    "    'min_samples_split' : [2, 3, 4, 5],\n",
    "    'min_samples_leaf' : [1, 2, 3, 4, 5],\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "clf = GridSearchCV(model, param_grid = param_grid, refit=True, verbose=3)\n",
    "best_clf = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 60, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "print(best_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for multiple columns in y_df (skipped)\n",
    "\n",
    "Already proven that decision trees can handle multiple columns in y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split training and testing set \n",
    "x_train, x_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print('\\n\\n\\n' + str(model))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with results from hyperparameter tuning\n",
    "model = RandomForestClassifier(max_depth=60, min_samples_leaf=1, min_samples_split=2, n_estimators=150)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print('\\n\\n\\n' + str(model))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/clf_red_wine.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model, '../models/clf_red_wine.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from aldrin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#define RandomForestClassifier Hyperparameters\n",
    "space = {'max_depth': hp.choice('max_depth', range(1,100)),\n",
    "         'criterion': hp.choice('criterion', [\"gini\",\"entropy\",\"log_loss\"]),\n",
    "         'n_estimators': hp.choice('n_estimators', range(1,100))\n",
    "        }\n",
    "\n",
    "#define target function\n",
    "def objective(params):\n",
    "\n",
    "#create model instance with params\n",
    "    model = RandomForestClassifier(**params)\n",
    "\n",
    "#train model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "#evaluate and return model score\n",
    "\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "    \n",
    "    # Extract the best score\n",
    "    best_score = max(scores)\n",
    "\n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "#minimize target function with hyperopt\n",
    "best = fmin(objective,\n",
    "            space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=200)\n",
    "\n",
    "best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a49e87bce5bd802686f26dd4b878e0d9c48fb847ebaa3a4b8cb7a6577b2fe3d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
